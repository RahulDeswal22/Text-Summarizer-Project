{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hp\\\\Text-Summarizer-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hp\\\\Text-Summarizer-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: Path\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: float\n",
    "    gradient_accumulation_steps: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_ckpt = config.model_ckpt,\n",
    "            num_train_epochs = params.num_train_epochs,\n",
    "            warmup_steps = params.warmup_steps,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size,\n",
    "            weight_decay = params.weight_decay,\n",
    "            logging_steps = params.logging_steps,\n",
    "            evaluation_strategy = params.evaluation_strategy,\n",
    "            eval_steps = params.evaluation_strategy,\n",
    "            save_steps = params.save_steps,\n",
    "            gradient_accumulation_steps = params.gradient_accumulation_steps\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-17 17:46:42,873: INFO: config: PyTorch version 2.2.2 available.]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "        \n",
    "        #loading data \n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "\n",
    "        # trainer_args = TrainingArguments(\n",
    "        #     output_dir=self.config.root_dir, num_train_epochs=self.config.num_train_epochs, warmup_steps=self.config.warmup_steps,\n",
    "        #     per_device_train_batch_size=self.config.per_device_train_batch_size, per_device_eval_batch_size=self.config.per_device_train_batch_size,\n",
    "        #     weight_decay=self.config.weight_decay, logging_steps=self.config.logging_steps,\n",
    "        #     evaluation_strategy=self.config.evaluation_strategy, eval_steps=self.config.eval_steps, save_steps=1e6,\n",
    "        #     gradient_accumulation_steps=self.config.gradient_accumulation_steps\n",
    "        # ) \n",
    "\n",
    "\n",
    "        trainer_args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir, num_train_epochs=1, warmup_steps=500,\n",
    "            per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "            weight_decay=0.01, logging_steps=10,\n",
    "            evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "            gradient_accumulation_steps=16\n",
    "        ) \n",
    "\n",
    "        trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"train\"], \n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
    "        \n",
    "        trainer.train()\n",
    "\n",
    "        ## Save model\n",
    "        model_pegasus.save_pretrained(os.path.join(self.config.root_dir,\"pegasus-samsum-model\"))\n",
    "        ## Save tokenizer\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir,\"tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-17 18:07:21,823: INFO: common: yaml file: config\\config.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-17 18:07:21,837: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-17 18:07:21,840: INFO: common: created directory at: artifacts]\n",
      "[2024-06-17 18:07:21,846: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6478687247463186bc4c5c3b753a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1995, 'grad_norm': 20.48751449584961, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 3.2262, 'grad_norm': 9.711017608642578, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n",
      "{'loss': 2.9224, 'grad_norm': 11.304835319519043, 'learning_rate': 3e-06, 'epoch': 0.03}\n",
      "{'loss': 2.853, 'grad_norm': 13.299054145812988, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 2.6911, 'grad_norm': 11.871971130371094, 'learning_rate': 5e-06, 'epoch': 0.05}\n",
      "{'loss': 2.729, 'grad_norm': 23.833356857299805, 'learning_rate': 6e-06, 'epoch': 0.07}\n",
      "{'loss': 2.6316, 'grad_norm': 10.161120414733887, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 2.4347, 'grad_norm': 9.823800086975098, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 2.5044, 'grad_norm': 7.497169494628906, 'learning_rate': 9e-06, 'epoch': 0.1}\n",
      "{'loss': 2.467, 'grad_norm': 6.793668270111084, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2325, 'grad_norm': 8.96264934539795, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1758, 'grad_norm': 6.3379011154174805, 'learning_rate': 1.2e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1534, 'grad_norm': 8.759004592895508, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 2.1061, 'grad_norm': 7.473703384399414, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.15}\n",
      "{'loss': 2.02, 'grad_norm': 8.633268356323242, 'learning_rate': 1.5e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9763, 'grad_norm': 32.81879806518555, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0109, 'grad_norm': 18.109634399414062, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0173, 'grad_norm': 7.700382709503174, 'learning_rate': 1.8e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8946, 'grad_norm': 4.851282119750977, 'learning_rate': 1.9e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9261, 'grad_norm': 10.21042251586914, 'learning_rate': 2e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8865, 'grad_norm': 5.641373157501221, 'learning_rate': 2.1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.79, 'grad_norm': 4.453788757324219, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8793, 'grad_norm': 5.052816390991211, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7813, 'grad_norm': 4.04083776473999, 'learning_rate': 2.4e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8354, 'grad_norm': 4.670814514160156, 'learning_rate': 2.5e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7816, 'grad_norm': 5.029804706573486, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7218, 'grad_norm': 5.134103298187256, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7512, 'grad_norm': 5.15428352355957, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8618, 'grad_norm': 5.409088134765625, 'learning_rate': 2.9e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6773, 'grad_norm': 5.940909385681152, 'learning_rate': 3e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8574, 'grad_norm': 6.4041619300842285, 'learning_rate': 3.1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8925, 'grad_norm': 6.45241641998291, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8061, 'grad_norm': 4.966202259063721, 'learning_rate': 3.3e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7383, 'grad_norm': 4.595344066619873, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7274, 'grad_norm': 8.334944725036621, 'learning_rate': 3.5e-05, 'epoch': 0.38}\n",
      "{'loss': 1.6552, 'grad_norm': 5.697684288024902, 'learning_rate': 3.6e-05, 'epoch': 0.39}\n",
      "{'loss': 1.6926, 'grad_norm': 5.300842761993408, 'learning_rate': 3.7e-05, 'epoch': 0.4}\n",
      "{'loss': 1.6898, 'grad_norm': 4.844779968261719, 'learning_rate': 3.8e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7203, 'grad_norm': 3.819350481033325, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7116, 'grad_norm': 5.474185943603516, 'learning_rate': 4e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7211, 'grad_norm': 6.579054355621338, 'learning_rate': 4.1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.6462, 'grad_norm': 4.3287553787231445, 'learning_rate': 4.2e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7876, 'grad_norm': 5.7445969581604, 'learning_rate': 4.3e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7123, 'grad_norm': 5.857101917266846, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.48}\n",
      "{'loss': 1.6619, 'grad_norm': 4.295877933502197, 'learning_rate': 4.5e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7152, 'grad_norm': 3.4269564151763916, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.5}\n",
      "{'loss': 1.6674, 'grad_norm': 4.5818986892700195, 'learning_rate': 4.7e-05, 'epoch': 0.51}\n",
      "{'loss': 1.6377, 'grad_norm': 8.781657218933105, 'learning_rate': 4.8e-05, 'epoch': 0.52}\n",
      "{'loss': 1.6481, 'grad_norm': 4.209730625152588, 'learning_rate': 4.9e-05, 'epoch': 0.53}\n",
      "{'loss': 1.6579, 'grad_norm': 3.515462875366211, 'learning_rate': 5e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d8202f9a644ac497f2eef7223d6cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/818 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4850271940231323, 'eval_runtime': 1263.5113, 'eval_samples_per_second': 0.647, 'eval_steps_per_second': 0.647, 'epoch': 0.54}\n",
      "{'loss': 1.7053, 'grad_norm': 4.268325328826904, 'learning_rate': 4.880952380952381e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6668, 'grad_norm': 3.2583422660827637, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6925, 'grad_norm': 3.8473622798919678, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5671, 'grad_norm': 5.758591175079346, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6613, 'grad_norm': 3.9351396560668945, 'learning_rate': 4.404761904761905e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6979, 'grad_norm': 5.0593581199646, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7027, 'grad_norm': 7.10544490814209, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6329, 'grad_norm': 3.5524168014526367, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5351, 'grad_norm': 5.152397632598877, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.64}\n",
      "{'loss': 1.6433, 'grad_norm': 4.005782604217529, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.65}\n",
      "{'loss': 1.562, 'grad_norm': 5.927016735076904, 'learning_rate': 3.690476190476191e-05, 'epoch': 0.66}\n",
      "{'loss': 1.6833, 'grad_norm': 4.609201431274414, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.67}\n",
      "{'loss': 1.6545, 'grad_norm': 3.8150742053985596, 'learning_rate': 3.4523809523809526e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6064, 'grad_norm': 4.858364582061768, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5037, 'grad_norm': 6.13270902633667, 'learning_rate': 3.2142857142857144e-05, 'epoch': 0.71}\n",
      "{'loss': 1.5693, 'grad_norm': 3.1517562866210938, 'learning_rate': 3.095238095238095e-05, 'epoch': 0.72}\n",
      "{'loss': 1.5813, 'grad_norm': 3.807197093963623, 'learning_rate': 2.9761904761904762e-05, 'epoch': 0.73}\n",
      "{'loss': 1.5956, 'grad_norm': 4.0849080085754395, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.74}\n",
      "{'loss': 1.5508, 'grad_norm': 3.209458112716675, 'learning_rate': 2.7380952380952383e-05, 'epoch': 0.75}\n",
      "{'loss': 1.6422, 'grad_norm': 3.5065696239471436, 'learning_rate': 2.6190476190476192e-05, 'epoch': 0.76}\n",
      "{'loss': 1.5801, 'grad_norm': 3.103769302368164, 'learning_rate': 2.5e-05, 'epoch': 0.77}\n",
      "{'loss': 1.5655, 'grad_norm': 2.986144542694092, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.78}\n",
      "{'loss': 1.5333, 'grad_norm': 2.987212657928467, 'learning_rate': 2.261904761904762e-05, 'epoch': 0.79}\n",
      "{'loss': 1.6766, 'grad_norm': 3.3721554279327393, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.8}\n",
      "{'loss': 1.57, 'grad_norm': 5.035257339477539, 'learning_rate': 2.023809523809524e-05, 'epoch': 0.81}\n",
      "{'loss': 1.5955, 'grad_norm': 4.211121559143066, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.83}\n",
      "{'loss': 1.5476, 'grad_norm': 4.027068138122559, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.84}\n",
      "{'loss': 1.5764, 'grad_norm': 5.893372535705566, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.85}\n",
      "{'loss': 1.5637, 'grad_norm': 7.781467914581299, 'learning_rate': 1.5476190476190476e-05, 'epoch': 0.86}\n",
      "{'loss': 1.6632, 'grad_norm': 15.91942024230957, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.87}\n",
      "{'loss': 1.5361, 'grad_norm': 2.849755048751831, 'learning_rate': 1.3095238095238096e-05, 'epoch': 0.88}\n",
      "{'loss': 1.606, 'grad_norm': 98.86212158203125, 'learning_rate': 1.1904761904761905e-05, 'epoch': 0.89}\n",
      "{'loss': 1.6891, 'grad_norm': 3.42179274559021, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.9}\n",
      "{'loss': 1.555, 'grad_norm': 3.936593532562256, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.91}\n",
      "{'loss': 1.5466, 'grad_norm': 6.291192054748535, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.92}\n",
      "{'loss': 1.5571, 'grad_norm': 3.887887477874756, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.93}\n",
      "{'loss': 1.5839, 'grad_norm': 4.09218168258667, 'learning_rate': 5.9523809523809525e-06, 'epoch': 0.94}\n",
      "{'loss': 1.5369, 'grad_norm': 5.432347774505615, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.96}\n",
      "{'loss': 1.54, 'grad_norm': 4.5140299797058105, 'learning_rate': 3.5714285714285714e-06, 'epoch': 0.97}\n",
      "{'loss': 1.597, 'grad_norm': 4.120645999908447, 'learning_rate': 2.3809523809523808e-06, 'epoch': 0.98}\n",
      "{'loss': 1.5156, 'grad_norm': 4.252754211425781, 'learning_rate': 1.1904761904761904e-06, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6163, 'grad_norm': 3.763716697692871, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 119827.716, 'train_samples_per_second': 0.123, 'train_steps_per_second': 0.008, 'train_loss': 1.8227204094762388, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
